{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline vs Naive: Fraud Detection Benefits Demo\n",
    "\n",
    "**8 real scenarios demonstrating why Pipeline outperforms traditional LLM approaches for fraud detection.**\n",
    "\n",
    "### Architecture Comparison\n",
    "\n",
    "| Approach | How it works | Token usage |\n",
    "|----------|-------------|-------------|\n",
    "| **Naive** | ALL transactions + 500 historical cases → LLM → predictions | ~23,000 tokens/batch |\n",
    "| **Pipeline** | ALL transactions → **Code Filters** → suspicious subset → **LLM sub-call** → predictions | ~300-700 tokens/batch |\n",
    "\n",
    "### Pipeline Loop (4 phases)\n",
    "```\n",
    "PROBE    → Examine data structure (0 LLM tokens)\n",
    "FILTER   → Run deterministic fraud filters (0 LLM tokens)\n",
    "ANALYZE  → LLM sub-calls on flagged subset only (minimal tokens)\n",
    "AGGREGATE → Merge results + cross-check (0 LLM tokens)\n",
    "```\n",
    "\n",
    "---\n",
    "*Results generated from live API calls (gpt-4o-mini). Cached for reproducibility.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Load cached results and scenario metadata\n",
    "with open(Path(\"demo_cache.json\")) as f:\n",
    "    cache = json.load(f)\n",
    "\n",
    "with open(Path(\"../data/demo_scenarios.json\")) as f:\n",
    "    scenarios = json.load(f)\n",
    "\n",
    "txns = pd.read_csv(Path(\"../data/demo_examples.csv\"))\n",
    "txns['timestamp'] = pd.to_datetime(txns['timestamp'], unit='s')\n",
    "\n",
    "print(f\"Loaded {len(scenarios)} scenarios, {len(txns)} transactions\")\n",
    "print(f\"Scenarios: {[s['name'] for s in scenarios]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build aggregate comparison table\n",
    "rows = []\n",
    "for s in scenarios:\n",
    "    sid = str(s['id'])\n",
    "    r = cache[sid]\n",
    "    rows.append({\n",
    "        'Scenario': f\"{s['id']}. {s['name']}\",\n",
    "        'Txns': s['num_transactions'],\n",
    "        'Fraud': s['num_fraud'],\n",
    "        'Naive Tokens': f\"{r['naive']['tokens']:,}\",\n",
    "        'Pipeline Tokens': f\"{r['pipeline']['tokens']:,}\",\n",
    "        'Token Savings': f\"{(1 - r['pipeline']['tokens'] / r['naive']['tokens']) * 100:.1f}%\" if r['naive']['tokens'] > 0 else \"100%\",\n",
    "        'Naive Acc': f\"{r['naive']['accuracy']['accuracy'] * 100:.0f}%\",\n",
    "        'Pipeline Acc': f\"{r['pipeline']['accuracy']['accuracy'] * 100:.0f}%\",\n",
    "        'Naive Cost': f\"${r['naive']['cost']:.4f}\",\n",
    "        'Pipeline Cost': f\"${r['pipeline']['cost']:.6f}\",\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "summary_df.style.set_caption(\"Naive vs Pipeline — All 8 Scenarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate totals\n",
    "total_naive_tokens = sum(cache[str(s['id'])]['naive']['tokens'] for s in scenarios)\n",
    "total_pipeline_tokens = sum(cache[str(s['id'])]['pipeline']['tokens'] for s in scenarios)\n",
    "total_naive_cost = sum(cache[str(s['id'])]['naive']['cost'] for s in scenarios)\n",
    "total_pipeline_cost = sum(cache[str(s['id'])]['pipeline']['cost'] for s in scenarios)\n",
    "\n",
    "naive_correct = sum(\n",
    "    cache[str(s['id'])]['naive']['accuracy']['tp'] + cache[str(s['id'])]['naive']['accuracy']['tn']\n",
    "    for s in scenarios\n",
    ")\n",
    "pipeline_correct = sum(\n",
    "    cache[str(s['id'])]['pipeline']['accuracy']['tp'] + cache[str(s['id'])]['pipeline']['accuracy']['tn']\n",
    "    for s in scenarios\n",
    ")\n",
    "total_txns = sum(s['num_transactions'] for s in scenarios)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AGGREGATE RESULTS (8 scenarios, 51 transactions)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<20} {'Naive':>12} {'Pipeline':>12} {'Savings':>12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Tokens':<20} {total_naive_tokens:>12,} {total_pipeline_tokens:>12,} {(1-total_pipeline_tokens/total_naive_tokens)*100:>11.1f}%\")\n",
    "print(f\"{'Cost':<20} {'$'+f'{total_naive_cost:.4f}':>12} {'$'+f'{total_pipeline_cost:.4f}':>12} {(1-total_pipeline_cost/total_naive_cost)*100:>11.1f}%\")\n",
    "print(f\"{'Accuracy':<20} {naive_correct}/{total_txns} ({naive_correct/total_txns*100:.1f}%){'':<2} {pipeline_correct}/{total_txns} ({pipeline_correct/total_txns*100:.1f}%){'':>2}\")\n",
    "print(f\"{'LLM Sub-calls':<20} {'1 monolithic':>12} {'per-user':>12}\")\n",
    "print(f\"{'Audit Trail':<20} {'None':>12} {'Full COT':>12}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "names = [s['name'] for s in scenarios]\n",
    "x = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "# --- Token Usage ---\n",
    "naive_tokens = [cache[str(s['id'])]['naive']['tokens'] for s in scenarios]\n",
    "pipeline_tokens = [cache[str(s['id'])]['pipeline']['tokens'] for s in scenarios]\n",
    "\n",
    "axes[0].bar(x - width/2, naive_tokens, width, label='Naive', color='#e74c3c', alpha=0.8)\n",
    "axes[0].bar(x + width/2, pipeline_tokens, width, label='Pipeline', color='#2ecc71', alpha=0.8)\n",
    "axes[0].set_ylabel('Tokens')\n",
    "axes[0].set_title('Token Usage per Scenario')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n",
    "axes[0].legend()\n",
    "axes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x/1000:.0f}K'))\n",
    "\n",
    "# --- Cost ---\n",
    "naive_costs = [cache[str(s['id'])]['naive']['cost'] * 1000 for s in scenarios]  # in millicents\n",
    "pipeline_costs = [cache[str(s['id'])]['pipeline']['cost'] * 1000 for s in scenarios]\n",
    "\n",
    "axes[1].bar(x - width/2, naive_costs, width, label='Naive', color='#e74c3c', alpha=0.8)\n",
    "axes[1].bar(x + width/2, pipeline_costs, width, label='Pipeline', color='#2ecc71', alpha=0.8)\n",
    "axes[1].set_ylabel('Cost (millicents $)')\n",
    "axes[1].set_title('Cost per Scenario')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n",
    "axes[1].legend()\n",
    "\n",
    "# --- Accuracy ---\n",
    "naive_acc = [cache[str(s['id'])]['naive']['accuracy']['accuracy'] * 100 for s in scenarios]\n",
    "pipeline_acc = [cache[str(s['id'])]['pipeline']['accuracy']['accuracy'] * 100 for s in scenarios]\n",
    "\n",
    "axes[2].bar(x - width/2, naive_acc, width, label='Naive', color='#e74c3c', alpha=0.8)\n",
    "axes[2].bar(x + width/2, pipeline_acc, width, label='Pipeline', color='#2ecc71', alpha=0.8)\n",
    "axes[2].set_ylabel('Accuracy %')\n",
    "axes[2].set_title('Accuracy per Scenario')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n",
    "axes[2].set_ylim(60, 105)\n",
    "axes[2].axhline(y=100, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pipeline_benefits_charts.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario Deep Dives\n",
    "\n",
    "Each scenario below shows:\n",
    "1. **Input transactions** with ground truth labels\n",
    "2. **Pipeline trajectory** — the 4-phase REPL loop (PROBE → FILTER → ANALYZE → AGGREGATE)\n",
    "3. **Naive vs Pipeline comparison** — tokens, cost, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scenario(scenario, cache_data, txns_df):\n",
    "    \"\"\"Display a single scenario with full trajectory.\"\"\"\n",
    "    sid = scenario['id']\n",
    "    r = cache_data[str(sid)]\n",
    "    stxns = txns_df[txns_df['scenario_id'] == sid].copy()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"  SCENARIO {sid}: {scenario['name']}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"  {scenario['description']}\")\n",
    "    print(f\"  Why Pipeline wins: {scenario['why_pipeline_wins']}\")\n",
    "    print()\n",
    "\n",
    "    # Input transactions\n",
    "    print(\"  INPUT TRANSACTIONS:\")\n",
    "    print(\"  \" + \"-\" * 66)\n",
    "    for _, row in stxns.iterrows():\n",
    "        label = \"FRAUD\" if row['is_fraud'] else \"LEGIT\"\n",
    "        fraud_marker = \" <<<\" if row['is_fraud'] else \"\"\n",
    "        print(f\"  {row['transaction_id']}: ${row['amount']:>8.2f}  {row['category']:<14} \"\n",
    "              f\"{row['location']:<8} {row['device']:<8} [{label}]{fraud_marker}\")\n",
    "    print()\n",
    "\n",
    "    # Pipeline Trajectory\n",
    "    traj = r['pipeline']['trajectory']\n",
    "    print(\"  PIPELINE TRAJECTORY (Chain of Thought):\")\n",
    "    print(\"  \" + \"-\" * 66)\n",
    "    phase_icons = {'PROBE': '1. PROBE', 'FILTER': '2. FILTER', 'ANALYZE': '3. ANALYZE', 'AGGREGATE': '4. AGGREGATE'}\n",
    "    for step in traj['steps']:\n",
    "        phase_label = phase_icons.get(step['phase'], step['phase'])\n",
    "        tokens_label = f\"({step['tokens']} tokens)\" if step['tokens'] > 0 else \"(0 tokens - code only)\"\n",
    "        print(f\"\\n  [{phase_label}] {tokens_label}\")\n",
    "        # Show pseudo-code\n",
    "        for line in step['code'].split('\\n'):\n",
    "            print(f\"    > {line}\")\n",
    "        # Show output (truncate long ones)\n",
    "        output_lines = step['output'].split('\\n')\n",
    "        for line in output_lines[:6]:\n",
    "            print(f\"    {line}\")\n",
    "        if len(output_lines) > 6:\n",
    "            print(f\"    ... ({len(output_lines) - 6} more lines)\")\n",
    "    print()\n",
    "\n",
    "    # Comparison table\n",
    "    print(\"  COMPARISON:\")\n",
    "    print(\"  \" + \"-\" * 66)\n",
    "    print(f\"  {'Metric':<16} {'Naive':>14} {'Pipeline':>14} {'Savings':>14}\")\n",
    "    print(\"  \" + \"-\" * 66)\n",
    "\n",
    "    nt, rt = r['naive']['tokens'], r['pipeline']['tokens']\n",
    "    nc, rc = r['naive']['cost'], r['pipeline']['cost']\n",
    "    na, ra = r['naive']['accuracy']['accuracy'], r['pipeline']['accuracy']['accuracy']\n",
    "\n",
    "    tsav = f\"{(1 - rt/nt) * 100:.1f}%\" if nt > 0 else \"100%\"\n",
    "    csav = f\"{(1 - rc/nc) * 100:.1f}%\" if nc > 0 else \"100%\"\n",
    "\n",
    "    print(f\"  {'Tokens':<16} {nt:>14,} {rt:>14,} {tsav:>14}\")\n",
    "    print(f\"  {'Cost':<16} {'$'+f'{nc:.4f}':>14} {'$'+f'{rc:.6f}':>14} {csav:>14}\")\n",
    "    print(f\"  {'Accuracy':<16} {na*100:>13.0f}% {ra*100:>13.0f}%\")\n",
    "    print(f\"  {'Precision':<16} {r['naive']['accuracy']['precision']*100:>13.0f}% {r['pipeline']['accuracy']['precision']*100:>13.0f}%\")\n",
    "    print(f\"  {'Recall':<16} {r['naive']['accuracy']['recall']*100:>13.0f}% {r['pipeline']['accuracy']['recall']*100:>13.0f}%\")\n",
    "\n",
    "    # Filtered ratio\n",
    "    filtered = r['pipeline'].get('filtered_count', '?')\n",
    "    total = r['pipeline'].get('total_count', '?')\n",
    "    print(f\"\\n  Pipeline filtered: {filtered}/{total} txns sent to LLM \"\n",
    "          f\"({(1 - filtered/total)*100:.0f}% reduction)\" if isinstance(filtered, int) and isinstance(total, int) and total > 0 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Velocity Attack\n",
    "*5 transactions in 3 minutes — card testing pattern*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scenario(scenarios[0], cache, txns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Geographic Impossibility\n",
    "*NYC → Tokyo in 10 minutes — impossible travel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scenario(scenarios[1], cache, txns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Amount Spike\n",
    "*User averages $19 on groceries, suddenly spends $487 on jewelry*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scenario(scenarios[2], cache, txns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4: Account Takeover\n",
    "*Profile shifts: mobile→desktop, LA→Chicago, grocery→gift_cards*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scenario(scenarios[3], cache, txns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 5: Micro-Transaction Testing\n",
    "*8 automated $1-2 transactions in 2 minutes — bot card testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scenario(scenarios[4], cache, txns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 6: Legitimate High-Value (False Positive Test)\n",
    "*Consistent high-value user — should NOT be flagged*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scenario(scenarios[5], cache, txns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 7: Mixed Batch (Multi-User)\n",
    "*5 users, 15 transactions — 2 fraudulent users, 3 legitimate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scenario(scenarios[6], cache, txns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 8: Cross-Border Rapid\n",
    "*London → Paris → Tokyo → Sydney in 30 minutes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scenario(scenarios[7], cache, txns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cost Projection at Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost projection based on observed per-transaction costs\n",
    "total_txns_demo = sum(s['num_transactions'] for s in scenarios)\n",
    "naive_per_txn = total_naive_cost / total_txns_demo\n",
    "pipeline_per_txn = total_pipeline_cost / total_txns_demo\n",
    "\n",
    "print(\"COST PROJECTION AT SCALE\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"Per-transaction cost: Naive=${naive_per_txn:.6f}  Pipeline=${pipeline_per_txn:.6f}\")\n",
    "print()\n",
    "print(f\"{'Scale':<25} {'Naive/year':>14} {'Pipeline/year':>14} {'Annual Savings':>16}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for label, daily in [(\"1K txns/day\", 1_000), (\"10K txns/day\", 10_000),\n",
    "                      (\"100K txns/day\", 100_000), (\"1M txns/day\", 1_000_000)]:\n",
    "    yearly = daily * 365\n",
    "    naive_yr = naive_per_txn * yearly\n",
    "    pipeline_yr = pipeline_per_txn * yearly\n",
    "    savings = naive_yr - pipeline_yr\n",
    "    print(f\"{label:<25} ${naive_yr:>13,.0f} ${pipeline_yr:>13,.0f} ${savings:>15,.0f}\")\n",
    "\n",
    "print(\"\\n(Based on gpt-4o-mini pricing: $0.15/1M input, $0.60/1M output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Where Naive Fails (and Pipeline Doesn't)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scenarios where Naive got it wrong\n",
    "print(\"SCENARIOS WHERE NAIVE MADE ERRORS\")\n",
    "print(\"=\" * 65)\n",
    "for s in scenarios:\n",
    "    sid = str(s['id'])\n",
    "    r = cache[sid]\n",
    "    na = r['naive']['accuracy']\n",
    "    ra = r['pipeline']['accuracy']\n",
    "\n",
    "    if na['accuracy'] < 1.0:\n",
    "        print(f\"\\nScenario {s['id']}: {s['name']}\")\n",
    "        print(f\"  Naive: {na['accuracy']*100:.0f}% accuracy (FP={na['fp']}, FN={na['fn']})\")\n",
    "        print(f\"  Pipeline:   {ra['accuracy']*100:.0f}% accuracy (FP={ra['fp']}, FN={ra['fn']})\")\n",
    "\n",
    "        # Show which predictions differed\n",
    "        naive_preds = r['naive']['predictions']\n",
    "        pipeline_preds = r['pipeline']['predictions']\n",
    "        stxns = txns[txns['scenario_id'] == s['id']]\n",
    "\n",
    "        for i, (_, row) in enumerate(stxns.iterrows()):\n",
    "            if i < len(naive_preds) and i < len(pipeline_preds):\n",
    "                np_val = naive_preds[i]\n",
    "                rp_val = pipeline_preds[i]\n",
    "                truth = row['is_fraud']\n",
    "                if np_val != truth:\n",
    "                    err_type = \"FALSE POSITIVE\" if np_val and not truth else \"FALSE NEGATIVE\"\n",
    "                    print(f\"  >>> {row['transaction_id']}: ${row['amount']:.2f} {row['category']} \"\n",
    "                          f\"— Naive: {err_type}, Pipeline: CORRECT\")\n",
    "\n",
    "if all(cache[str(s['id'])]['naive']['accuracy']['accuracy'] == 1.0 for s in scenarios):\n",
    "    print(\"  Both approaches achieved 100% on all scenarios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Takeaways for Production\n",
    "\n",
    "### 1. Cost Reduction: 97%+\n",
    "Pipeline uses deterministic code filters to eliminate 50-100% of transactions before any LLM call. Only suspicious subsets reach the LLM, with fresh per-user context (no context rot).\n",
    "\n",
    "### 2. Accuracy: Same or Better\n",
    "Pipeline achieved **100% accuracy** across all 8 scenarios. Naive failed on 3 scenarios (false positives on legitimate users, missed fraud in mixed batches and cross-border patterns).\n",
    "\n",
    "### 3. Full Audit Trail\n",
    "Every pipeline decision has an executable code trace: which filter triggered, what thresholds were crossed, what the LLM verified. This is critical for **compliance** and **explainability** in financial services.\n",
    "\n",
    "### 4. Deterministic + Reliable\n",
    "Code filters produce the same result every run. No LLM variance in the filtering phase. LLM is only used for semantic judgment on pre-filtered data with temperature=0.\n",
    "\n",
    "### 5. Scales Without Context Window Limits  \n",
    "Naive stuffs everything into one prompt (hits token limits at scale). Pipeline processes per-user with context folding — handles millions of transactions by filtering first, then making targeted sub-calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualization: Token efficiency\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "labels = ['Naive\\n(500 cases + all txns → LLM)', 'Pipeline\\n(Code filters → LLM on subset)']\n",
    "values = [total_naive_tokens, total_pipeline_tokens]\n",
    "colors = ['#e74c3c', '#2ecc71']\n",
    "\n",
    "bars = ax.barh(labels, values, color=colors, height=0.5, alpha=0.85)\n",
    "ax.set_xlabel('Total Tokens (8 scenarios, 51 transactions)')\n",
    "ax.set_title('Total Token Usage: Naive vs Pipeline')\n",
    "\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(bar.get_width() + 500, bar.get_y() + bar.get_height()/2,\n",
    "            f'{val:,} tokens', va='center', fontweight='bold')\n",
    "\n",
    "ax.set_xlim(0, max(values) * 1.25)\n",
    "ax.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x/1000:.0f}K'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pipeline_token_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "pct = (1 - total_pipeline_tokens / total_naive_tokens) * 100\n",
    "print(f\"\\nPipeline uses {pct:.1f}% fewer tokens than Naive across all scenarios.\")\n",
    "print(f\"Naive: {total_naive_tokens:,} tokens (${total_naive_cost:.4f})\")\n",
    "print(f\"Pipeline:   {total_pipeline_tokens:,} tokens (${total_pipeline_cost:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}